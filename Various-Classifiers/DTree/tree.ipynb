{
 "metadata": {
  "name": "",
  "signature": "sha256:f7553cdf1937fb35558f50596b005f771bf957d0b33a6c3a06757a17eca20770"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Preprocessing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import re\n",
      "from scipy import io\n",
      "import numpy as np\n",
      "import time\n",
      "\n",
      "NUM_TRAINING_EXAMPLES = 5172\n",
      "NUM_TEST_EXAMPLES = 5857\n",
      "\n",
      "BASE_DIR = 'spam-dataset/'\n",
      "SPAM_DIR = 'spam/'\n",
      "HAM_DIR = 'ham/'\n",
      "TEST_DIR = 'test/'\n",
      "\n",
      "NUM_PRUNE = 10\n",
      "\n",
      "spam = glob.glob(BASE_DIR + SPAM_DIR + '*.txt')\n",
      "ham = glob.glob(BASE_DIR + HAM_DIR + '*.txt')\n",
      "test = [BASE_DIR + TEST_DIR + str(x) + '.txt' for x in range(NUM_TEST_EXAMPLES)]\n",
      "\n",
      "words_table = {}\n",
      "unique_words = 0\n",
      "words_prune = []\n",
      "\n",
      "for filename in (spam + ham):\n",
      "    with open(filename) as f:\n",
      "        text = f.read() # Read in text from file\n",
      "        text = text.replace('\\r\\n', ' ') # Remove newline character\n",
      "        words = re.findall(r'\\w+', text)\n",
      "\n",
      "        for word in words:\n",
      "            if word in words_table:\n",
      "                words_table[word] += 1\n",
      "            else:\n",
      "                words_table[word] = 1\n",
      "\n",
      "# prune words < num_prune, rebuild index\n",
      "for word in words_table:\n",
      "    if words_table[word] < NUM_PRUNE:\n",
      "        words_prune.append(word)\n",
      "    else:\n",
      "        words_table[word] = unique_words\n",
      "        unique_words += 1\n",
      "\n",
      "for word in words_prune:\n",
      "    words_table.pop(word)\n",
      "\n",
      "design_matrix = []\n",
      "test_matrix = []\n",
      "labels = []\n",
      "num_attrs = len(words_table)\n",
      "\n",
      "for filename in spam:\n",
      "    with open(filename) as f:\n",
      "        text = f.read() # Read in text from file\n",
      "        text = text.replace('\\r\\n', ' ') # Remove newline character\n",
      "        words = re.findall(r'\\w+', text)\n",
      "        doc = np.zeros(num_attrs)\n",
      "\n",
      "        for word in words:\n",
      "            if word in words_table:\n",
      "                attr = words_table[word]\n",
      "                doc[attr] += 1\n",
      "\n",
      "    design_matrix.append(doc)\n",
      "    labels.append(1)\n",
      "\n",
      "for filename in ham:\n",
      "    with open(filename) as f:\n",
      "        text = f.read() # Read in text from file\n",
      "        text = text.replace('\\r\\n', ' ') # Remove newline character\n",
      "        words = re.findall(r'\\w+', text)\n",
      "        doc = np.zeros(num_attrs)\n",
      "\n",
      "        for word in words:\n",
      "            if word in words_table:\n",
      "                attr = words_table[word]\n",
      "                doc[attr] += 1\n",
      "\n",
      "    design_matrix.append(doc)\n",
      "    labels.append(0)   \n",
      "\n",
      "for filename in test:\n",
      "    with open(filename) as f:\n",
      "        text = f.read() # Read in text from file\n",
      "        text = text.replace('\\r\\n', ' ') # Remove newline character\n",
      "        words = re.findall(r'\\w+', text)\n",
      "        doc = np.zeros(num_attrs)\n",
      "\n",
      "        for word in words:\n",
      "            if word in words_table:\n",
      "                attr = words_table[word]\n",
      "                doc[attr] += 1\n",
      "\n",
      "    test_matrix.append(doc)\n",
      "\n",
      "design_matrix = np.asarray(design_matrix)\n",
      "test_matrix = np.asarray(test_matrix)\n",
      "labels = np.asarray([labels])\n",
      "\n",
      "file_dict = {}\n",
      "file_dict['training_data'] = design_matrix\n",
      "file_dict['training_labels'] = labels\n",
      "file_dict['test_data'] = test_matrix\n",
      "io.savemat('spam_data_bagofwords.mat', file_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Decision Tree and Random Forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RAW_DATA_SPAM = io.loadmat('spam_data_bagofwords.mat')\n",
      "SPAM_TRAINING_DATA = RAW_DATA_SPAM['training_data']\n",
      "SPAM_TRAINING_LABELS = RAW_DATA_SPAM['training_labels'][0]\n",
      "SPAM_TEST_DATA = RAW_DATA_SPAM['test_data']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LeafNode(object):\n",
      "    def __init__(self, l):\n",
      "        self.label = l\n",
      "        \n",
      "    def get_label(self):\n",
      "        return self.label\n",
      "    \n",
      "    def is_leaf(self):\n",
      "        return True\n",
      "\n",
      "class Node(object):\n",
      "    def __init__(self, split, l=None, r=None):\n",
      "        self.split_rule = split\n",
      "        self.left_node = l\n",
      "        self.right_node = r\n",
      "        \n",
      "    def set_left(self, node):\n",
      "        self.left_node = node\n",
      "        \n",
      "    def set_right(self, node):\n",
      "        self.right_node = node\n",
      "        \n",
      "    def get_left(self):\n",
      "        return self.left_node\n",
      "        \n",
      "    def get_right(self):\n",
      "        return self.right_node\n",
      "    \n",
      "    def get_rule(self):\n",
      "        return self.split_rule\n",
      "    \n",
      "    def is_leaf(self):\n",
      "        return False\n",
      "        \n",
      "class DTree(object):\n",
      "    def __init__(self, d, i, s):\n",
      "        self.root = None\n",
      "        self.max_depth = d\n",
      "        self.impurity = i\n",
      "        self.segmentor = s\n",
      "        \n",
      "    def train(self, data, labels):\n",
      "        def grow(data, labels, depth):\n",
      "            if len(set(labels)) == 1:\n",
      "                return LeafNode(labels[0])\n",
      "            \n",
      "            if depth >= self.max_depth:\n",
      "                num_spam = np.sum(labels)\n",
      "                \n",
      "                if num_spam > labels.size - num_spam:\n",
      "                    return LeafNode(1)\n",
      "                else:\n",
      "                    return LeafNode(0)\n",
      "                \n",
      "            segment = self.segmentor(data, labels, self.impurity)\n",
      "            \n",
      "            idx_left = []            \n",
      "            idx_right = []\n",
      "            \n",
      "            data_count = 0\n",
      "            \n",
      "            for s in data:\n",
      "                if s[segment[0]] < segment[1]:\n",
      "                    idx_left.append(data_count)\n",
      "                else:\n",
      "                    idx_right.append(data_count)\n",
      "                    \n",
      "                data_count += 1\n",
      "                    \n",
      "            data_left = data[idx_left]\n",
      "            labels_left = labels[idx_left]\n",
      "            \n",
      "            data_right = data[idx_right]\n",
      "            labels_right = labels[idx_right]\n",
      "            \n",
      "            if data_left.size == 0:\n",
      "                return LeafNode(labels_right[0])\n",
      "            elif data_right.size == 0:\n",
      "                return LeafNode(labels_left[0])\n",
      "            else:\n",
      "                return Node(segment, grow(data_left, labels_left, depth + 1), grow(data_right, labels_right, depth + 1))\n",
      "            \n",
      "        self.root = grow(data, labels, 0)\n",
      "    \n",
      "    def predict(self, data):\n",
      "        predicted_labels = []\n",
      "        \n",
      "        for s in data:\n",
      "            node = self.root\n",
      "            \n",
      "            while not node.is_leaf():\n",
      "                rule = node.get_rule()\n",
      "                \n",
      "                if s[rule[0]] < rule[1]:\n",
      "                    node = node.get_left()\n",
      "                else:\n",
      "                    node = node.get_right()\n",
      "                    \n",
      "            predicted_labels.append(node.get_label())\n",
      "            \n",
      "        return np.asarray(predicted_labels)\n",
      "    \n",
      "\n",
      "class RandomForest(object):\n",
      "    def __init__(self, d, i, s):\n",
      "        self.forest = []\n",
      "        self.max_depth = d\n",
      "        self.impurity = i\n",
      "        self.segmentor = s\n",
      "        \n",
      "    def train(self, data, labels, num_trees=5):\n",
      "        for i in range(num_trees):\n",
      "            random_idx = np.random.choice(labels.size, labels.size)\n",
      "            sampled_data = data[random_idx]\n",
      "            sampled_labels = labels[random_idx]\n",
      "            \n",
      "            tree = DTree(self.max_depth, self.impurity, self.segmentor)\n",
      "            tree.train(sampled_data, sampled_labels)\n",
      "            \n",
      "            self.forest.append(tree)\n",
      "    \n",
      "    def predict(self, data):\n",
      "        predicted_labels = []\n",
      "        polls = []\n",
      "\n",
      "        for tree in self.forest:\n",
      "            tree_predictions = tree.predict(data)\n",
      "            polls.append(tree_predictions)\n",
      "            \n",
      "        polls = np.asarray(polls)\n",
      "        \n",
      "        for results in polls.T:\n",
      "            num_spam = np.sum(results)\n",
      "            \n",
      "            if num_spam > results.size - num_spam:\n",
      "                predicted_labels.append(1)\n",
      "            else:\n",
      "                predicted_labels.append(0)\n",
      "            \n",
      "        return np.asarray(predicted_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def impurity_func(left_label_hist, right_label_hist):\n",
      "    spam_left, spam_right = left_label_hist['spam'], right_label_hist['spam']\n",
      "    ham_left, ham_right = left_label_hist['ham'], right_label_hist['ham']\n",
      "    sample_left, sample_right = spam_left + ham_left, spam_right + ham_right\n",
      "    spam = spam_left + spam_right\n",
      "    ham = ham_left + ham_right\n",
      "    sample = spam + ham\n",
      "    \n",
      "#     parent_entropy = -1 * (((spam / sample) * np.log2(spam / sample)) + ((ham / sample) * np.log2(ham / sample)))\n",
      "    parent_entropy = 1 - (spam / sample) ** 2 - (ham / sample) ** 2\n",
      "    \n",
      "    if sample_left == 0.0:\n",
      "        left_entropy = 1\n",
      "    else:\n",
      "#         left_entropy = -1 * (((spam_left / sample_left) * np.log2(spam_left / sample_left)) + ((ham_left / sample_left) * np.log2(ham_left / sample_left)))\n",
      "        left_entropy = 1 - (spam_left / sample_left) ** 2 - (ham_left / sample_left) ** 2\n",
      "        \n",
      "    if sample_right == 0.0:\n",
      "        right_entropy = 1\n",
      "    else:\n",
      "#         right_entropy = -1 * (((spam_right / sample_right) * np.log2(spam_right / sample_right)) + ((ham_right / sample_right) * np.log2(ham_right / sample_right)))    \n",
      "        right_entropy = 1 - (spam_right / sample_right) ** 2 - (ham_right / sample_right) ** 2\n",
      "    \n",
      "    return parent_entropy - (((sample_left / sample) * left_entropy) + ((sample_right / sample) * right_entropy))\n",
      "    \n",
      "# info gain via brute force\n",
      "def segmentor_func_ig(data, labels, impurity):\n",
      "    best_attr = 0\n",
      "    best_info_gain = 0.0\n",
      "    threshold = 0\n",
      "    attr_idx = 0\n",
      "        \n",
      "    for attr in data.T:\n",
      "        for n in set(attr):\n",
      "            left_hist = {'spam': 0.0, 'ham': 0.0}\n",
      "            right_hist = {'spam': 0.0, 'ham': 0.0}\n",
      "            sample_idx = 0\n",
      "            \n",
      "            for s in data:\n",
      "                if s[attr_idx] < n:\n",
      "                    if labels[sample_idx] == 1:\n",
      "                        left_hist['spam'] += 1\n",
      "                    else:\n",
      "                        left_hist['ham'] += 1\n",
      "                else:\n",
      "                    if labels[sample_idx] == 1:\n",
      "                        right_hist['spam'] += 1\n",
      "                    else:\n",
      "                        right_hist['ham'] += 1\n",
      "                        \n",
      "                sample_idx += 1\n",
      "                        \n",
      "            info_gain = impurity_func(left_hist, right_hist)\n",
      "\n",
      "            if info_gain > best_info_gain:\n",
      "                best_attr = attr_idx\n",
      "                best_info_gain = info_gain\n",
      "                threshold = n\n",
      "        \n",
      "        attr_idx += 1\n",
      "    \n",
      "    return (best_attr, threshold)\n",
      "\n",
      "# info gain via brute force with random attribute selection\n",
      "def segmentor_func_igr(data, labels, impurity):\n",
      "    best_attr = 0\n",
      "    best_info_gain = 0.0\n",
      "    threshold = 0\n",
      "    attr_idx = 0\n",
      "    \n",
      "    random_idx = np.random.choice(labels.size, labels.size / 2, replace=False)\n",
      "    \n",
      "    for attr in data.T[random_idx]:\n",
      "        for n in set(attr):\n",
      "            left_hist = {'spam': 0.0, 'ham': 0.0}\n",
      "            right_hist = {'spam': 0.0, 'ham': 0.0}\n",
      "            sample_idx = 0\n",
      "            \n",
      "            for s in data:\n",
      "                if s[attr_idx] < n:\n",
      "                    if labels[sample_idx] == 1:\n",
      "                        left_hist['spam'] += 1\n",
      "                    else:\n",
      "                        left_hist['ham'] += 1\n",
      "                else:\n",
      "                    if labels[sample_idx] == 1:\n",
      "                        right_hist['spam'] += 1\n",
      "                    else:\n",
      "                        right_hist['ham'] += 1\n",
      "                        \n",
      "                sample_idx += 1\n",
      "                        \n",
      "            info_gain = impurity_func(left_hist, right_hist)\n",
      "\n",
      "            if info_gain > best_info_gain:\n",
      "                best_attr = attr_idx\n",
      "                best_info_gain = info_gain\n",
      "                threshold = n\n",
      "        \n",
      "        attr_idx += 1\n",
      "    \n",
      "    return (best_attr, threshold)\n",
      "\n",
      "# mean of means\n",
      "def segmentor_func_mom(data, labels, impurity):\n",
      "    best_attr = 0\n",
      "    best_info_gain = 0.0\n",
      "    threshold = 0\n",
      "    attr_idx = 0\n",
      "    \n",
      "    for attr in data.T:\n",
      "        mean_spam = 0.0\n",
      "        mean_ham = 0.0\n",
      "        spam_count = 0.0\n",
      "        ham_count = 0.0\n",
      "        \n",
      "        label_idx = 0\n",
      "        \n",
      "        for label in labels:\n",
      "            if label == 1:\n",
      "                mean_spam += attr[label_idx]\n",
      "                spam_count += 1\n",
      "            else:\n",
      "                mean_ham += attr[label_idx]\n",
      "                ham_count += 1\n",
      "                \n",
      "            label_idx += 1\n",
      "        \n",
      "        if spam_count == 0:\n",
      "            mom = (mean_ham / ham_count)\n",
      "        elif ham_count == 0:\n",
      "            mom = (mean_spam / spam_count)\n",
      "        else:\n",
      "            mom = ((mean_spam / spam_count) + (mean_ham / ham_count)) / 2.0\n",
      "        \n",
      "        left_hist = {'spam': 0.0, 'ham': 0.0}\n",
      "        right_hist = {'spam': 0.0, 'ham': 0.0}\n",
      "        sample_idx = 0\n",
      "            \n",
      "        for s in data:\n",
      "            if s[attr_idx] < mom:\n",
      "                if labels[sample_idx] == 1:\n",
      "                    left_hist['spam'] += 1\n",
      "                else:\n",
      "                    left_hist['ham'] += 1\n",
      "            else:\n",
      "                if labels[sample_idx] == 1:\n",
      "                    right_hist['spam'] += 1\n",
      "                else:\n",
      "                    right_hist['ham'] += 1\n",
      "\n",
      "            sample_idx += 1\n",
      "                    \n",
      "        info_gain = impurity_func(left_hist, right_hist)\n",
      "\n",
      "        if info_gain > best_info_gain:\n",
      "            best_attr = attr_idx\n",
      "            best_info_gain = info_gain\n",
      "            threshold = mom\n",
      "        \n",
      "        attr_idx += 1\n",
      "\n",
      "    return (best_attr, threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy(actual, predicted):\n",
      "    hits = 0.0\n",
      "    \n",
      "    for i in range(actual.size):\n",
      "        if actual[i] == predicted[i]:\n",
      "            hits += 1\n",
      "            \n",
      "    return hits / actual.size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RANDOM_IDX = np.random.choice(5172, 4672, replace=False)\n",
      "\n",
      "TRAIN_DATA_SET = SPAM_TRAINING_DATA[RANDOM_IDX]\n",
      "TRAIN_LABEL_SET = SPAM_TRAINING_LABELS[RANDOM_IDX]\n",
      "TEST_DATA_SET = np.delete(SPAM_TRAINING_DATA, RANDOM_IDX, axis=0)\n",
      "TEST_LABEL_SET = np.delete(SPAM_TRAINING_LABELS, RANDOM_IDX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "\n",
      "tree = DTree(200, impurity_func, segmentor_func_ig)\n",
      "tree.train(TRAIN_DATA_SET, TRAIN_LABEL_SET)\n",
      "\n",
      "end = time.clock()\n",
      "print end - start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "977.865997\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = tree.predict(TEST_DATA_SET)\n",
      "accuracy(TEST_LABEL_SET, predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.824"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.clock()\n",
      "\n",
      "forest = RandomForest(200, impurity_func, segmentor_func_igr)\n",
      "forest.train(TRAIN_DATA_SET, TRAIN_LABEL_SET, 10)\n",
      "\n",
      "end = time.clock()\n",
      "print end - start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training tree 0\n",
        "\n",
        "training tree 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 6\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 8\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training tree 9\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1730.560801"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = forest.predict(TEST_DATA_SET)\n",
      "accuracy(TEST_LABEL_SET, predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.88"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Examination of Decision Tree and Random Forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_dtree_point = SPAM_TRAINING_DATA[666]\n",
      "test_dtree_node = tree.root\n",
      "dtree_common_attr = []\n",
      "\n",
      "while not test_dtree_node.is_leaf():\n",
      "    rule = test_dtree_node.get_rule()\n",
      "    dtree_common_attr.append(rule)\n",
      "                \n",
      "    if test_dtree_point[rule[0]] < rule[1]:\n",
      "        test_dtree_node = test_dtree_node.get_left()\n",
      "    else:\n",
      "        test_dtree_node = test_dtree_node.get_right()\n",
      "\n",
      "print \"predicted label: %d\" % test_dtree_node.get_label()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "predicted label: 1\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for split in dtree_common_attr:\n",
      "    for word in words_table:\n",
      "        if words_table[word] == split[0]:\n",
      "            print \"Attribute \" + str(split[0]) + \" (\\\"\" + str(word) + \"\\\") < \" + str(split[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Attribute 4298 (\"enron\") < 1.0\n",
        "Attribute 700 (\"http\") < 1.0\n",
        "Attribute 2749 (\"thanks\") < 1.0\n",
        "Attribute 5449 (\"hpl\") < 1.0\n",
        "Attribute 2605 (\"meter\") < 1.0\n",
        "Attribute 5552 (\"attached\") < 1.0\n",
        "Attribute 4138 (\"gas\") < 1.0\n",
        "Attribute 5756 (\"2001\") < 1.0\n",
        "Attribute 1335 (\"questions\") < 1.0\n",
        "Attribute 6092 (\"daren\") < 1.0\n",
        "Attribute 2905 (\"mmbtu\") < 1.0\n",
        "Attribute 515 (\"neon\") < 1.0\n",
        "Attribute 3261 (\"sitara\") < 1.0\n",
        "Attribute 688 (\"ken\") < 1.0\n",
        "Attribute 5755 (\"2000\") < 1.0\n",
        "Attribute 5260 (\"your\") < 1.0\n",
        "Attribute 2725 (\"yvette\") < 1.0\n",
        "Attribute 6115 (\"713\") < 1.0\n",
        "Attribute 5267 (\"valid\") < 1.0\n",
        "Attribute 1234 (\"spirit\") < 1.0\n",
        "Attribute 2272 (\"hr\") < 1.0\n",
        "Attribute 760 (\"resume\") < 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Attribute 1114 (\"saturday\") < 1.0\n",
        "Attribute 3074 (\"unify\") < 1.0\n",
        "Attribute 4301 (\"julie\") < 1.0\n",
        "Attribute 5418 (\"employee\") < 1.0\n",
        "Attribute 8 (\"errors\") < 2.0\n",
        "Attribute 15 (\"music\") < 9.0\n",
        "Attribute 188 (\"ehronline\") < 1.0\n",
        "Attribute 453 (\"request\") < 3.0\n",
        "Attribute 567 (\"bryan\") < 1.0\n",
        "Attribute 1056 (\"288\") < 2.0\n",
        "Attribute 1378 (\"rsvp\") < 1.0\n",
        "Attribute 1764 (\"logistics\") < 1.0\n",
        "Attribute 3361 (\"ua\") < 2.0\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Random Forest Top Level Split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_forest_common_attr = set()\n",
      "\n",
      "for tree in forest.forest:\n",
      "    random_forest_common_attr.add(tree.root.split_rule[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in words_table:\n",
      "    if words_table[word] in random_forest_common_attr:\n",
      "        print word"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http\n",
        "ect\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Kaggle"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "def save_csv(filename, labels):\n",
      "    with open(filename, 'wb') as csvfile:\n",
      "        writer = csv.writer(csvfile, delimiter=\",\")\n",
      "        writer.writerow([\"Id\", \"Category\"])\n",
      "        count = 1\n",
      "        \n",
      "        for pred in labels:\n",
      "            writer.writerow([count, pred])\n",
      "            count+=1\n",
      "            \n",
      "def kaggle(filename, data, model):\n",
      "    pred = model.predict(data)\n",
      "    save_csv(filename, pred.tolist())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = DTree(200, impurity_func, segmentor_func_ig)\n",
      "tree.train(SPAM_TRAINING_DATA, SPAM_TRAINING_LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kaggle(\"tree_try2_bf.csv\", SPAM_TEST_DATA, tree)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest = RandomForest(10, impurity_func, segmentor_func_igr)\n",
      "forest.train(SPAM_TRAINING_DATA, SPAM_TRAINING_LABELS, 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kaggle(\"forest.csv\", SPAM_TEST_DATA, forest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}